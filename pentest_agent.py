import asyncio
import os
import base64
import json
import re # Import re for regex
from typing import Any # Import Any
from playwright.async_api import async_playwright, Page # Import Page for type hinting
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, FunctionMessage # Import FunctionMessage
from langchain_core.output_parsers import JsonOutputParser # Import JsonOutputParser
from langchain_core.runnables import RunnablePassthrough # Import RunnablePassthrough
from utils import draw_bounding_boxes, check_vulnerabilities, generate_report
import imageio
from pydantic import BaseModel, Field, RootModel # Import RootModel
from src.agent_tools.tools import AgentTools # Import AgentTools
from src.browser_controller.controller import BrowserController # Import BrowserController
import logging # Import logging
import os # Import os for environment variables

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_json_from_markdown(text: str) -> str:
    """
    Extracts a JSON string from a markdown code block or a plain string that might
    be wrapped in extra quotes.
    """
    # Regex to find a JSON code block
    match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
    if match:
        return match.group(1).strip()
    
    # If not a markdown code block, try to remove leading/trailing quotes
    # and then attempt to parse as JSON to validate
    cleaned_text = text.strip()
    if cleaned_text.startswith('"') and cleaned_text.endswith('"'):
        cleaned_text = cleaned_text[1:-1]
    
    # Attempt to parse to ensure it's valid JSON, if not, return original
    try:
        json.loads(cleaned_text)
        return cleaned_text
    except json.JSONDecodeError:
        return text # Return original if not valid JSON after cleaning

# --- State Representation ---

class TabInfo(BaseModel):
    url: str
    title: str

class PageInfo(BaseModel):
    viewport_width: int
    viewport_height: int
    page_width: int
    page_height: int
    scroll_x: int
    scroll_y: int

class Vulnerability(BaseModel):
    label: str = Field(..., description="A concise title for the vulnerability.")
    severity: str = Field(..., description="The severity of the vulnerability (e.g., 'Low', 'Medium', 'High', 'Critical').")
    description: str = Field(..., description="A detailed description of the specific issue.")
    owasp_category: str = Field(..., description="The relevant OWASP category (e.g., 'A05:2021 - Security Misconfiguration').")

class VulnerabilityReport(RootModel):
    root: list[Vulnerability] = Field(..., description="A list of identified vulnerabilities.")

class BrowserStateSummary(BaseModel):
    url: str
    title: str
    tabs: list[TabInfo]
    page_info: PageInfo
    report: list[Vulnerability] # Use the Pydantic model for the report


class PentestAgent:
    def __init__(self, websocket, task):
        self.websocket = websocket
        self.task = task
        self.history = []
        self.frames = []
        self.final_pentest_report = "No report generated."
        self.browser_controller: BrowserController | None = None
        self.agent_tools: AgentTools | None = None
        self.intermediate_steps = [] # To store tool outputs
        self.llm_with_tools = None # Initialize here, bind in run

        if task.model == 'gemini':
            self.client = ChatGoogleGenerativeAI(
                model=task.geminiModel,
                google_api_key=task.geminiApiKey,
                config={
                    "response_mime_type": "application/json"
                },
            )
        else:
            self.client = ChatOpenAI(
                model=task.openaiModel,
                openai_api_key=task.openaiApiKey,
                model_kwargs={"response_format": {"type": "json_object"}}
            )
        
        # Bind the LLM to the Pydantic model for structured output
        self.llm_with_structured_output = self.client.with_structured_output(VulnerabilityReport)

    async def run(self):
        await self.send_log(f"[PENTEST AGENT] Starting task: {self.task.instruction}")

        system_prompt = """
        You are an expert penetration tester. Your goal is to find vulnerabilities in the web application.
        You will be given a URL and a task. You need to perform penetration testing on the given URL.
        You have access to a browser and can use the provided tools to interact with it, gather information, and verify vulnerabilities.
        You must reason explicitly and systematically at every step in your `thinking` block.
        Use the tools to navigate, interact with elements, and gather information.
        If you identify potential vulnerabilities, describe them and suggest further actions or report them.
        The `BrowserStateSummary` will now include a `report` field which is a JSON array of identified vulnerabilities.
        
        **IMPORTANT**: When you are finished with your analysis and are not calling a tool, your final response MUST be ONLY a JSON array of vulnerability objects, strictly adhering to the `VulnerabilityReport` Pydantic model. 
        - DO NOT include any conversational text, explanations, or markdown outside of the JSON array.
        - Each object in the array MUST represent a single, distinct vulnerability.
        - DO NOT nest multiple vulnerabilities in the `description` of a single vulnerability object. Each vulnerability should be its own object in the array.

        Output of report should follow below example of a final JSON response:
        ```json
        [
          {
            "label": "Insecure Form Submission",
            "severity": "High",
            "description": "The login form submits data over HTTP instead of HTTPS, exposing sensitive user credentials to potential interception.",
            "owasp_category": "A05:2021 - Security Misconfiguration"
          },
          {
            "label": "Reflected Cross-Site Scripting (XSS)",
            "severity": "High",
            "description": "The search input field is vulnerable to reflected XSS, allowing attackers to inject malicious scripts. Input validation and output encoding are required.",
            "owasp_category": "A03:2021 - Injection"
          }
        ]
        ```
        If no specific vulnerabilities are found, return an empty array `[]`.

        You can use the following tools:
        - navigate(url: str): Navigates the browser to the specified URL.
        - click_element(description: str): Clicks an element on the page identified by a description.
        - type_text(text: str, input_field_description: str): Types text into an input field or textarea identified by a description.
        - scroll_page(direction: str): Scrolls the page up or down. Direction can be 'up' or 'down'.
        - get_page_content(): Returns the full HTML content of the current page.
        - finish_task(summary: str): Marks the task as finished and provides a summary.
        """

        self.history.append(SystemMessage(content=system_prompt))
        self.history.append(HumanMessage(content=f"The task is: {self.task.instruction}"))

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            self.browser_controller = BrowserController(page)
            self.agent_tools = AgentTools(self.browser_controller)
            
            # The LLM will directly call methods from self.agent_tools
            # No explicit binding needed here as the LLM will be prompted to use these methods
            self.llm_with_tools = self.client # Keep the client for direct LLM calls

            await self.browser_controller.navigate(self.task.url)

            for step_count in range(15): # Increased step limit
                logging.info(f"Agent Step: {step_count + 1}")
                
                # Observe the current state
                browser_state = await self.observe(page)
                # Retrieve dom_state directly from the browser controller for screenshot
                dom_state_for_screenshot = await self.browser_controller.get_dom_state()
                screenshot_bytes = await self.send_screenshot(page, dom_state_for_screenshot)
                image_b64 = base64.b64encode(screenshot_bytes).decode()
                
                # Prepare messages for the LLM
                messages = [
                    HumanMessage(content=[
                        {"type": "text", "text": browser_state.model_dump_json()},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
                    ])
                ] + self.intermediate_steps # Include previous tool outputs

                # Get LLM's next action
                llm_response = await self.llm_with_tools.ainvoke(messages)
                
                logging.info(f"LLM Response: {llm_response}")
                
                if llm_response.tool_calls:
                    tool_call = llm_response.tool_calls[0]
                    tool_name = tool_call['name']
                    tool_args = tool_call['args']
                    
                    await self.send_log(f"[PENTEST AGENT] Calling tool: {tool_name} with args: {tool_args}")
                    
                    try:
                        tool_method = getattr(self.agent_tools, tool_name)
                        tool_result = await tool_method(**tool_args)
                        self.intermediate_steps.append(FunctionMessage(name=tool_name, content=str(tool_result)))
                        await self.send_log(f"[PENTEST AGENT] Tool result: {tool_result}")
                    except Exception as e:
                        error_message = f"Error calling tool '{tool_name}': {e}"
                        logging.error(error_message)
                        self.intermediate_steps.append(FunctionMessage(name=tool_name, content=f'{{"error": "{error_message}"}}'))
                        await self.send_log(f"[PENTEST AGENT] Tool error: {error_message}")
                else:
                    # If LLM doesn't call a tool, it's providing a text response (e.g., a report or analysis)
                    # Use the structured output for the final report
                    try:
                        # Attempt to parse the LLM's response content as JSON
                        parsed_report = json.loads(llm_response.content)
                    except (json.JSONDecodeError, TypeError) as e:
                        logging.error(f"Failed to parse LLM report as JSON: {e}. Raw content: {llm_response.content}")
                        # Fallback to an error report if parsing fails
                        parsed_report = [{
                            "label": "LLM Report Parsing Error",
                            "severity": "Informational",
                            "description": f"The LLM's final response could not be parsed into a valid JSON format. Raw content: {llm_response.content}",
                            "owasp_category": "N/A"
                        }]
                    
                    self.final_pentest_report = json.dumps(parsed_report, indent=2)
                    await self.send_log(f"[PENTEST AGENT] LLM Analysis: {self.final_pentest_report}")
                    break # End the loop if LLM provides a final analysis

            await browser.close()

        await self.send_log("[FINAL_PENTEST_AGENT] Task finished. Saving video...")
        video_filename = "pentest_agent_run.mp4"
        imageio.mimsave(video_filename, self.frames, fps=3)
        await self.send_log(f"[VIDEO]/{video_filename}")
        await self.send_log("[DONE]")

        return self.history, video_filename, self.final_pentest_report

    async def observe(self, page: Page):
        page_state = await page.evaluate("""
            () => {
                return {
                    url: window.location.href,
                    title: document.title,
                    viewport_width: window.innerWidth,
                    viewport_height: window.innerHeight,
                    page_width: document.body.scrollWidth,
                    page_height: document.body.scrollHeight,
                    scroll_x: window.scrollX,
                    scroll_y: window.scrollY,
                }
            }
        """)

        tabs = []
        for p in page.context.pages:
            tabs.append(TabInfo(url=p.url, title=await p.title()))

        # The dom_state is now retrieved directly from the browser controller
        dom_state = await self.browser_controller.get_dom_state()
        
        vulnerabilities = check_vulnerabilities(dom_state)
        report_list = generate_report(vulnerabilities)
        self.final_pentest_report = json.dumps(report_list, indent=2) # Store the final report as a JSON string

        return BrowserStateSummary(
            url=page_state["url"],
            title=page_state["title"],
            tabs=tabs,
            page_info=PageInfo(**page_state),
            report=report_list # Pass the list of dictionaries directly
        )

    async def send_log(self, message):
        await self.websocket.send_text(message)

    async def send_screenshot(self, page, elements):
        screenshot_bytes = await page.screenshot(type='jpeg', quality=95)
        self.frames.append(imageio.imread(screenshot_bytes))
        
        screenshot_with_boxes = draw_bounding_boxes(screenshot_bytes, elements)
        await self.websocket.send_bytes(screenshot_with_boxes)
        return screenshot_bytes